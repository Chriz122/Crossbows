# æ¨¡å‹æ”¹é€²èªªæ˜æ–‡ä»¶

## å•é¡Œè¨ºæ–·
åŸæ¨¡å‹åœ¨è¨“ç·´é›†ä¸Šè¡¨ç¾è‰¯å¥½,ä½†é æ¸¬æ™‚å‡ºç¾æ˜é¡¯åç§»å’Œå¹³æ»‘èª¤å·®,å±¬æ–¼å…¸å‹çš„ã€Œ**éæ“¬åˆ + æ™‚åºæ³›åŒ–ä¸è¶³**ã€å•é¡Œã€‚

---

## ğŸ¯ ä¸»è¦æ”¹é€²æªæ–½

### 1ï¸âƒ£ **æ¨¡å‹çµæ§‹æ”¹é€² - BiLSTM + Dropout**

#### æ”¹é€²å‰:
```python
self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
```

#### æ”¹é€²å¾Œ:
```python
self.lstm = nn.LSTM(input_size, hidden_size, num_layers, 
                   batch_first=True, bidirectional=True, dropout=0.3)
```

**å„ªé»:**
- âœ… **BiLSTM(é›™å‘LSTM)**: åŒæ™‚æ•æ‰å‰å‘å’Œå¾Œå‘æ™‚åºä¿¡æ¯,å¢å¼·æ™‚åºè¨˜æ†¶èƒ½åŠ›
- âœ… **Dropout (0.3)**: é˜²æ­¢éæ“¬åˆ,æå‡æ³›åŒ–èƒ½åŠ›
- âœ… **å…¨é€£æ¥å±¤æ·»åŠ  ReLU + Dropout**: å¢åŠ éç·šæ€§è¡¨é”èƒ½åŠ›ä¸¦æ­£å‰‡åŒ–

**åƒæ•¸èª¿æ•´:**
- `hidden_size`: 512 â†’ 256 (é™ä½å®¹é‡,æ¸›å°‘éæ“¬åˆ)
- `num_layers`: 3 â†’ 2 (ç°¡åŒ–çµæ§‹,åŠ å¿«è¨“ç·´)

---

### 2ï¸âƒ£ **è¼¸å…¥ç‰¹å¾µå¢å¼· - å‹•æ…‹ä¿¡æ¯èåˆ**

#### æ”¹é€²å‰:
- åªä½¿ç”¨éœæ…‹é—œéµé»ä½ç½® (63ç¶­)

#### æ”¹é€²å¾Œ:
```python
# è¨ˆç®—é€Ÿåº¦ (ä¸€éšå·®åˆ†)
velocity = np.diff(dataX, axis=1)

# è¨ˆç®—åŠ é€Ÿåº¦ (äºŒéšå·®åˆ†)
acceleration = np.diff(velocity, axis=1)

# èåˆç‰¹å¾µ: ä½ç½® + é€Ÿåº¦ + åŠ é€Ÿåº¦
dataX_enhanced = np.concatenate([dataX, velocity, acceleration], axis=2)
# æœ€çµ‚ç‰¹å¾µç¶­åº¦: 63 + 63 + 63 = 189ç¶­
```

**å„ªé»:**
- âœ… æä¾›æ‰‹éƒ¨**é‹å‹•å‹•æ…‹ä¿¡æ¯**,è€Œéå–®å¹€éœæ…‹å§¿æ…‹
- âœ… æ¨¡å‹èƒ½å­¸ç¿’åˆ°**ä½ç½®è®ŠåŒ–è¶¨å‹¢**
- âœ… æ›´ç¬¦åˆçœŸå¯¦çš„ç‰©ç†é‹å‹•è¦å¾‹

---

### 3ï¸âƒ£ **æå¤±å‡½æ•¸æ”¹é€² - Smooth L1 + å‹•æ…‹èª¤å·®æ‡²ç½°**

#### æ”¹é€²å‰:
```python
criterion = nn.MSELoss()
```

#### æ”¹é€²å¾Œ:
```python
criterion = nn.SmoothL1Loss()  # Huber Loss

def combined_loss(pred, target, prev_pred, prev_target):
    # ä½ç½®èª¤å·®
    pos_loss = criterion(pred, target)
    
    # è§’é€Ÿåº¦èª¤å·® (é¼“å‹µæ™‚é–“é€£çºŒæ€§)
    pred_velocity = pred - prev_pred
    target_velocity = target - prev_target
    velocity_loss = criterion(pred_velocity, target_velocity)
    
    return pos_loss + 0.5 * velocity_loss
```

**å„ªé»:**
- âœ… **Smooth L1 Loss**: å°é›¢ç¾¤å€¼æ›´ç©©å¥,ä¸æœƒéåº¦å¹³æ»‘
- âœ… **å‹•æ…‹èª¤å·®æ‡²ç½°**: è®“æ¨¡å‹å­¸ç¿’**è§’é€Ÿåº¦è®ŠåŒ–è¶¨å‹¢**,è€Œéåªé—œæ³¨çµ•å°å€¼
- âœ… æå‡é æ¸¬çš„æ™‚é–“é€£è²«æ€§

---

### 4ï¸âƒ£ **è¨“ç·´ç­–ç•¥å„ªåŒ–**

#### æ–°å¢åŠŸèƒ½:

**A. æ¢¯åº¦è£å‰ª**
```python
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
```
- é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸,ç©©å®šè¨“ç·´

**B. Early Stopping**
```python
patience = 50  # 50å€‹epochæ²’æ”¹å–„å°±åœæ­¢
if test_loss < best_test_loss:
    best_test_loss = test_loss
    best_model_state = model.state_dict().copy()
else:
    patience_counter += 1
```
- é˜²æ­¢éåº¦è¨“ç·´,è‡ªå‹•é¸æ“‡æœ€ä½³æ¨¡å‹

**C. å­¸ç¿’ç‡èª¿æ•´**
```python
lr: 0.00001 â†’ 0.0001
betas: (0.5, 0.999) â†’ (0.9, 0.999)
```
- åŠ å¿«æ”¶æ–‚é€Ÿåº¦,æå‡è¨“ç·´ç©©å®šæ€§

---

## ğŸ“Š æ¨¡å‹åƒæ•¸å°æ¯”

| é …ç›® | æ”¹é€²å‰ | æ”¹é€²å¾Œ |
|------|--------|--------|
| **LSTMé¡å‹** | å–®å‘LSTM | BiLSTM |
| **è¼¸å…¥ç‰¹å¾µ** | 63ç¶­ (ä½ç½®) | 189ç¶­ (ä½ç½®+é€Ÿåº¦+åŠ é€Ÿåº¦) |
| **Hidden Size** | 512 | 256 |
| **LSTMå±¤æ•¸** | 3 | 2 |
| **Dropout** | ç„¡ | 0.3 |
| **æå¤±å‡½æ•¸** | MSELoss | SmoothL1Loss + é€Ÿåº¦æ‡²ç½° |
| **å…¨é€£æ¥å±¤** | [128,128,128,64,3] | [256,128,64,3] + Dropout |
| **æ­£å‰‡åŒ–** | ç„¡ | Dropout + æ¢¯åº¦è£å‰ª |
| **Early Stopping** | ç„¡ | âœ“ (patience=50) |

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. è¨“ç·´æ–°æ¨¡å‹
```powershell
cd c:\Users\USER\Desktop\Crossbows
python cnn_lstm/train.py
```

è¨“ç·´éç¨‹æœƒ:
- è‡ªå‹•æª¢æŸ¥ GPU å¯ç”¨æ€§
- æ¯50å€‹epochè¼¸å‡ºä¸€æ¬¡æå¤±å’ŒAPæŒ‡æ¨™
- ç•¶æ¸¬è©¦æå¤±ä¸å†ä¸‹é™æ™‚è‡ªå‹•åœæ­¢
- ä¿å­˜æœ€ä½³æ¨¡å‹åˆ° `RUN/train/cnn_lstm_model.pth`

### 2. ä½¿ç”¨æ¨¡å‹é æ¸¬
```powershell
python cnn_lstm/predict.py
```

é æ¸¬çµæœæœƒä¿å­˜åˆ°:
- `RUN/predict/final_prediction_results.csv`
- `RUN/predict/predictions_plot.png`

---

## ğŸ” é æœŸæ•ˆæœ

æ”¹é€²å¾Œçš„æ¨¡å‹æ‡‰è©²èƒ½:

1. âœ… **æ¸›å°‘é æ¸¬åç§»**: BiLSTM æ•æ‰é›™å‘æ™‚åºä¾è³´
2. âœ… **æå‡æ™‚åºé€£è²«æ€§**: å‹•æ…‹èª¤å·®æ‡²ç½°ç´„æŸè§’é€Ÿåº¦è®ŠåŒ–
3. âœ… **é™ä½éæ“¬åˆ**: Dropout + Early Stopping
4. âœ… **æ›´ç©©å®šçš„é æ¸¬**: Smooth L1 Loss ä¸æœƒéåº¦å¹³æ»‘
5. âœ… **æ›´å¿«æ”¶æ–‚**: å„ªåŒ–çš„å­¸ç¿’ç‡å’Œåƒæ•¸è¦æ¨¡

---

## ğŸ“ é€²ä¸€æ­¥æ”¹é€²å»ºè­°

å¦‚æœæ•ˆæœä»ä¸ç†æƒ³,å¯ä»¥å˜—è©¦:

### A. æ•¸æ“šå¢å¼·
```python
# å°æ‰‹éƒ¨é—œéµé»æ·»åŠ è¼•å¾®æ“¾å‹•
noise = np.random.normal(0, 0.01, features.shape)
features_augmented = features + noise
```

### B. å˜—è©¦ Transformer
```python
# ä½¿ç”¨ Self-Attention å»ºæ¨¡å…¨åºåˆ—ä¾è³´
encoder_layer = nn.TransformerEncoderLayer(d_model=189, nhead=3)
transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)
```

### C. å¤šæ¨¡æ…‹èåˆ
å¦‚æœæœ‰é™€èºå„€æ•¸æ“š,å¯ä»¥:
```python
# CNN è™•ç†æ‰‹éƒ¨é—œéµé»
# LSTM è™•ç† IMU æ™‚åº
# ä¸­é–“å±¤èåˆ
```

### D. èª¿æ•´åºåˆ—é•·åº¦
```python
# å˜—è©¦ä¸åŒçš„ time_step
time_step = 20  # æˆ–æ›´é•·çš„æ­·å²çª—å£
```

---

## âš ï¸ æ³¨æ„äº‹é …

1. **è¨˜æ†¶é«”éœ€æ±‚**: BiLSTM æœƒå¢åŠ è¨˜æ†¶é«”ä½¿ç”¨,å¦‚æœ GPU è¨˜æ†¶é«”ä¸è¶³,å¯ä»¥:
   - é™ä½ `batch_size`
   - é™ä½ `hidden_size`

2. **è¨“ç·´æ™‚é–“**: BiLSTM è¨“ç·´è¼ƒæ…¢,ä½† Early Stopping æœƒåŠ é€Ÿ

3. **æ¨¡å‹å…¼å®¹æ€§**: 
   - è¨“ç·´å’Œé æ¸¬çš„æ¨¡å‹çµæ§‹å¿…é ˆå®Œå…¨ä¸€è‡´
   - å·²åŒæ­¥æ›´æ–° `train.py` å’Œ `predict.py`

4. **æ•¸æ“šæ¨™æº–åŒ–**:
   - é æ¸¬æ™‚éœ€è¦ä½¿ç”¨èˆ‡è¨“ç·´æ™‚ç›¸åŒçš„æ¨™æº–åŒ–æ–¹æ³•
   - ç›®å‰ä½¿ç”¨ `MinMaxScaler` 

---

## ğŸ“ ç–‘é›£æ’è§£

### Q1: é¡¯ç¤ºè¨˜æ†¶é«”ä¸è¶³
```python
# é™ä½ batch_size
batch_size = 64  # æˆ– 32
```

### Q2: è¨“ç·´å¤ªæ…¢
```python
# æ¸›å°‘å±¤æ•¸æˆ–éš±è—å–®å…ƒ
hidden_size = 128
num_layers = 1
```

### Q3: é æ¸¬çµæœä»æœ‰åç§»
- æª¢æŸ¥æ•¸æ“šæ¨™æº–åŒ–æ˜¯å¦ä¸€è‡´
- å˜—è©¦èª¿æ•´ `lambda_velocity` æ¬Šé‡
- å¢åŠ è¨“ç·´æ•¸æ“šé‡

---

**æ”¹é€²å®Œæˆæ—¥æœŸ**: 2025å¹´10æœˆ31æ—¥
**æ”¹é€²è€…**: GitHub Copilot
